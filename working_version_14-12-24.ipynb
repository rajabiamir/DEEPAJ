{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xB6Ex0DOxlE",
        "outputId": "8f40a592-cc0d-4dd1-c8b7-71260b746d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sae'...\n",
            "remote: Enumerating objects: 662, done.\u001b[K\n",
            "remote: Counting objects: 100% (662/662), done.\u001b[K\n",
            "remote: Compressing objects: 100% (279/279), done.\u001b[K\n",
            "remote: Total 662 (delta 392), reused 641 (delta 376), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (662/662), 20.79 MiB | 22.13 MiB/s, done.\n",
            "Resolving deltas: 100% (392/392), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Acciorocketships/sae.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd sae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JrWFqt_P3K9",
        "outputId": "4197c77b-95e3-4063-e650-95632d90bdc4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sae\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP747dxVP3Nq",
        "outputId": "c78f7f21-96af-4ceb-a656-eedf3f585ca9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "-e option requires 1 argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n"
      ],
      "metadata": {
        "id": "zLnfVDi9P3P3"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sae import AutoEncoder"
      ],
      "metadata": {
        "id": "EfdbqZENhCI1"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "NgroPmgNeOMo"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneInteractionNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(GeneInteractionNN, self).__init__()\n",
        "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
        "        self.output = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.hidden(x))\n",
        "        x = torch.sigmoid(self.output(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "ObRkqH7seg6Y"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Autoencoder being trained for each gene across all individuals (each batch is a different ind)\n",
        "import torch\n",
        "from sae import AutoEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "num_individuals = 30\n",
        "num_genes = 15         #Number of genes per individual\n",
        "max_n = 200           #Max input dimension for each gene (discuss later)\n",
        "embedding_dim = 4     #latent space dimension\n",
        "epochs = 100\n",
        "\n",
        "# 1. Generating synthetic data in which each class has a different distribution\n",
        "group_0 = torch.normal(mean=1, std=0.4, size=(15, num_genes, max_n))\n",
        "group_1 = torch.normal(mean=1.5, std=0.3, size=(15, num_genes, max_n))\n",
        "\n",
        "data = torch.cat((group_0, group_1), dim=0)\n",
        "labels = torch.cat((torch.zeros(15), torch.ones(15)))\n",
        "\n",
        "\n",
        "data_scaled = torch.empty_like(data)\n",
        "scaler = StandardScaler()\n",
        "for gene_idx in range(num_genes):\n",
        "    gene_data = data[:, gene_idx, :]  # Shape: (30, max_n)\n",
        "    data_scaled[:, gene_idx, :] = torch.tensor(\n",
        "        scaler.fit_transform(gene_data), dtype=torch.float32\n",
        "    )\n",
        "\n",
        "#place holder for final embeddings: (num_individuals, num_genes * embedding_dim)\n",
        "final_embeddings = torch.empty((num_individuals, num_genes * embedding_dim))\n",
        "\n",
        "# 2. Training AutoEncoder for each gene\n",
        "for gene_idx in range(num_genes):\n",
        "    print(f\"Training autoencoder for Gene {gene_idx + 1}/{num_genes}\")\n",
        "\n",
        "    gene_data = data_scaled[:, gene_idx, :]\n",
        "\n",
        "    model = AutoEncoder(dim=max_n, hidden_dim=embedding_dim, max_n=max_n)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    batch = torch.arange(0, num_individuals)\n",
        "\n",
        "    #Training autoencoder\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #forward\n",
        "        _, batchr = model(gene_data, batch)\n",
        "        loss = model.loss()[\"loss\"]\n",
        "\n",
        "        #backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "    #extracting latent embeddings for the current gene\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model.encoder(gene_data, batch)  #shape: (num_individuals, embedding_dim)\n",
        "\n",
        "\n",
        "    final_embeddings[:, gene_idx * embedding_dim:(gene_idx + 1) * embedding_dim] = z\n",
        "\n",
        "\n",
        "print(\"Final Embeddings Shape:\", final_embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMc9wgK1SIb7",
        "outputId": "2f25d09e-67e5-488d-8b96-b8d48ff4f719"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training autoencoder for Gene 1/15\n",
            "Epoch 10/100, Loss: 0.3960404694080353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 0.35335826873779297\n",
            "Epoch 30/100, Loss: 0.31316134333610535\n",
            "Epoch 40/100, Loss: 0.27566424012184143\n",
            "Epoch 50/100, Loss: 100.77806091308594\n",
            "Epoch 60/100, Loss: 79.06385803222656\n",
            "Epoch 70/100, Loss: 66.37223052978516\n",
            "Epoch 80/100, Loss: 63.674415588378906\n",
            "Epoch 90/100, Loss: 62.52069854736328\n",
            "Epoch 100/100, Loss: 61.6512565612793\n",
            "Training autoencoder for Gene 2/15\n",
            "Epoch 10/100, Loss: 0.30938199162483215\n",
            "Epoch 20/100, Loss: 0.27877411246299744\n",
            "Epoch 30/100, Loss: 108.59234619140625\n",
            "Epoch 40/100, Loss: 100.84932708740234\n",
            "Epoch 50/100, Loss: 85.40225219726562\n",
            "Epoch 60/100, Loss: 66.30450439453125\n",
            "Epoch 70/100, Loss: 63.19626235961914\n",
            "Epoch 80/100, Loss: 61.25282287597656\n",
            "Epoch 90/100, Loss: 58.87060546875\n",
            "Epoch 100/100, Loss: 58.77933883666992\n",
            "Training autoencoder for Gene 3/15\n",
            "Epoch 10/100, Loss: 114.65299224853516\n",
            "Epoch 20/100, Loss: 90.00298309326172\n",
            "Epoch 30/100, Loss: 82.51826477050781\n",
            "Epoch 40/100, Loss: 78.42537689208984\n",
            "Epoch 50/100, Loss: 71.60430145263672\n",
            "Epoch 60/100, Loss: 66.11290740966797\n",
            "Epoch 70/100, Loss: 62.568260192871094\n",
            "Epoch 80/100, Loss: 58.459747314453125\n",
            "Epoch 90/100, Loss: 53.96076965332031\n",
            "Epoch 100/100, Loss: 49.45293045043945\n",
            "Training autoencoder for Gene 4/15\n",
            "Epoch 10/100, Loss: 86.23310089111328\n",
            "Epoch 20/100, Loss: 74.12835693359375\n",
            "Epoch 30/100, Loss: 65.85728454589844\n",
            "Epoch 40/100, Loss: 63.26430892944336\n",
            "Epoch 50/100, Loss: 60.504058837890625\n",
            "Epoch 60/100, Loss: 57.072265625\n",
            "Epoch 70/100, Loss: 54.04568862915039\n",
            "Epoch 80/100, Loss: 51.8502197265625\n",
            "Epoch 90/100, Loss: 48.2952995300293\n",
            "Epoch 100/100, Loss: 44.8016357421875\n",
            "Training autoencoder for Gene 5/15\n",
            "Epoch 10/100, Loss: 3.2535741329193115\n",
            "Epoch 20/100, Loss: 3.177834987640381\n",
            "Epoch 30/100, Loss: 3.1036083698272705\n",
            "Epoch 40/100, Loss: 3.029812812805176\n",
            "Epoch 50/100, Loss: 2.9565131664276123\n",
            "Epoch 60/100, Loss: 2.8839709758758545\n",
            "Epoch 70/100, Loss: 2.812433958053589\n",
            "Epoch 80/100, Loss: 2.7421000003814697\n",
            "Epoch 90/100, Loss: 2.6731154918670654\n",
            "Epoch 100/100, Loss: 2.605587959289551\n",
            "Training autoencoder for Gene 6/15\n",
            "Epoch 10/100, Loss: 74.06918334960938\n",
            "Epoch 20/100, Loss: 55.84852600097656\n",
            "Epoch 30/100, Loss: 48.89598846435547\n",
            "Epoch 40/100, Loss: 45.718624114990234\n",
            "Epoch 50/100, Loss: 41.459476470947266\n",
            "Epoch 60/100, Loss: 36.97988510131836\n",
            "Epoch 70/100, Loss: 33.50118637084961\n",
            "Epoch 80/100, Loss: 28.662107467651367\n",
            "Epoch 90/100, Loss: 28.609827041625977\n",
            "Epoch 100/100, Loss: 25.25103759765625\n",
            "Training autoencoder for Gene 7/15\n",
            "Epoch 10/100, Loss: 1.3928505182266235\n",
            "Epoch 20/100, Loss: 1.3299620151519775\n",
            "Epoch 30/100, Loss: 1.2684056758880615\n",
            "Epoch 40/100, Loss: 1.2098591327667236\n",
            "Epoch 50/100, Loss: 1.154540777206421\n",
            "Epoch 60/100, Loss: 1.1023662090301514\n",
            "Epoch 70/100, Loss: 1.0531580448150635\n",
            "Epoch 80/100, Loss: 1.0067164897918701\n",
            "Epoch 90/100, Loss: 0.962844729423523\n",
            "Epoch 100/100, Loss: 0.9213577508926392\n",
            "Training autoencoder for Gene 8/15\n",
            "Epoch 10/100, Loss: 1.3771164417266846\n",
            "Epoch 20/100, Loss: 1.318499207496643\n",
            "Epoch 30/100, Loss: 1.2626819610595703\n",
            "Epoch 40/100, Loss: 1.2097822427749634\n",
            "Epoch 50/100, Loss: 1.1597323417663574\n",
            "Epoch 60/100, Loss: 1.1123849153518677\n",
            "Epoch 70/100, Loss: 1.0675631761550903\n",
            "Epoch 80/100, Loss: 1.025084376335144\n",
            "Epoch 90/100, Loss: 0.9847726821899414\n",
            "Epoch 100/100, Loss: 0.9464624524116516\n",
            "Training autoencoder for Gene 9/15\n",
            "Epoch 10/100, Loss: 72.4305419921875\n",
            "Epoch 20/100, Loss: 52.8392333984375\n",
            "Epoch 30/100, Loss: 45.99275207519531\n",
            "Epoch 40/100, Loss: 42.70820617675781\n",
            "Epoch 50/100, Loss: 39.290069580078125\n",
            "Epoch 60/100, Loss: 33.17873764038086\n",
            "Epoch 70/100, Loss: 29.36941146850586\n",
            "Epoch 80/100, Loss: 25.631736755371094\n",
            "Epoch 90/100, Loss: 21.629405975341797\n",
            "Epoch 100/100, Loss: 17.671613693237305\n",
            "Training autoencoder for Gene 10/15\n",
            "Epoch 10/100, Loss: 80.57555389404297\n",
            "Epoch 20/100, Loss: 67.41934967041016\n",
            "Epoch 30/100, Loss: 64.48722076416016\n",
            "Epoch 40/100, Loss: 62.016475677490234\n",
            "Epoch 50/100, Loss: 58.94204330444336\n",
            "Epoch 60/100, Loss: 56.1077880859375\n",
            "Epoch 70/100, Loss: 53.509246826171875\n",
            "Epoch 80/100, Loss: 50.790985107421875\n",
            "Epoch 90/100, Loss: 48.811248779296875\n",
            "Epoch 100/100, Loss: 44.305458068847656\n",
            "Training autoencoder for Gene 11/15\n",
            "Epoch 10/100, Loss: 1.8826006650924683\n",
            "Epoch 20/100, Loss: 1.8379406929016113\n",
            "Epoch 30/100, Loss: 1.7924854755401611\n",
            "Epoch 40/100, Loss: 1.747112512588501\n",
            "Epoch 50/100, Loss: 1.702113389968872\n",
            "Epoch 60/100, Loss: 1.6575965881347656\n",
            "Epoch 70/100, Loss: 1.613588809967041\n",
            "Epoch 80/100, Loss: 1.5700697898864746\n",
            "Epoch 90/100, Loss: 1.5269874334335327\n",
            "Epoch 100/100, Loss: 1.4842647314071655\n",
            "Training autoencoder for Gene 12/15\n",
            "Epoch 10/100, Loss: 0.4858081042766571\n",
            "Epoch 20/100, Loss: 0.41876640915870667\n",
            "Epoch 30/100, Loss: 0.38708049058914185\n",
            "Epoch 40/100, Loss: 0.35745295882225037\n",
            "Epoch 50/100, Loss: 0.3301292359828949\n",
            "Epoch 60/100, Loss: 0.30502110719680786\n",
            "Epoch 70/100, Loss: 0.28195422887802124\n",
            "Epoch 80/100, Loss: 0.26074305176734924\n",
            "Epoch 90/100, Loss: 100.65888214111328\n",
            "Epoch 100/100, Loss: 99.02172088623047\n",
            "Training autoencoder for Gene 13/15\n",
            "Epoch 10/100, Loss: 2.231328010559082\n",
            "Epoch 20/100, Loss: 2.162482976913452\n",
            "Epoch 30/100, Loss: 2.0920908451080322\n",
            "Epoch 40/100, Loss: 2.0212292671203613\n",
            "Epoch 50/100, Loss: 1.9501559734344482\n",
            "Epoch 60/100, Loss: 1.878974437713623\n",
            "Epoch 70/100, Loss: 1.8077595233917236\n",
            "Epoch 80/100, Loss: 1.7365912199020386\n",
            "Epoch 90/100, Loss: 1.6655616760253906\n",
            "Epoch 100/100, Loss: 1.5947766304016113\n",
            "Training autoencoder for Gene 14/15\n",
            "Epoch 10/100, Loss: 0.8809394836425781\n",
            "Epoch 20/100, Loss: 0.8339434266090393\n",
            "Epoch 30/100, Loss: 0.7877528071403503\n",
            "Epoch 40/100, Loss: 0.7424583435058594\n",
            "Epoch 50/100, Loss: 0.6981290578842163\n",
            "Epoch 60/100, Loss: 0.6548243165016174\n",
            "Epoch 70/100, Loss: 0.6125994920730591\n",
            "Epoch 80/100, Loss: 0.5715131759643555\n",
            "Epoch 90/100, Loss: 0.5316264033317566\n",
            "Epoch 100/100, Loss: 0.49300336837768555\n",
            "Training autoencoder for Gene 15/15\n",
            "Epoch 10/100, Loss: 81.19328308105469\n",
            "Epoch 20/100, Loss: 66.8276138305664\n",
            "Epoch 30/100, Loss: 63.33331298828125\n",
            "Epoch 40/100, Loss: 61.419490814208984\n",
            "Epoch 50/100, Loss: 59.958213806152344\n",
            "Epoch 60/100, Loss: 58.22053909301758\n",
            "Epoch 70/100, Loss: 55.356658935546875\n",
            "Epoch 80/100, Loss: 51.59075927734375\n",
            "Epoch 90/100, Loss: 47.663414001464844\n",
            "Epoch 100/100, Loss: 44.16661071777344\n",
            "Final Embeddings Shape: torch.Size([30, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(final_embeddings.detach().numpy(), labels.numpy(), test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "CCmGvvpGSIeF"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
      ],
      "metadata": {
        "id": "3Hp2u5spSIgb"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The MLP part\n",
        "input_dim = final_embeddings.shape[1]\n",
        "hidden_dim = 12\n",
        "model = GeneInteractionNN(input_dim, hidden_dim)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(x_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyYjuOM0u1Mj",
        "outputId": "1f1eb61f-efeb-450c-a5d5-f56bd4717c53"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 0.46882691979408264\n",
            "Epoch 20/100, Loss: 0.29003143310546875\n",
            "Epoch 30/100, Loss: 0.19289427995681763\n",
            "Epoch 40/100, Loss: 0.1378091722726822\n",
            "Epoch 50/100, Loss: 0.10305505245923996\n",
            "Epoch 60/100, Loss: 0.07706446200609207\n",
            "Epoch 70/100, Loss: 0.057174187153577805\n",
            "Epoch 80/100, Loss: 0.04312387481331825\n",
            "Epoch 90/100, Loss: 0.03346600756049156\n",
            "Epoch 100/100, Loss: 0.02675621025264263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_test = model(x_test)\n",
        "    test_loss = criterion(y_pred_test, y_test)\n",
        "    print(f\"Test Loss: {test_loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BkWgDS_u1Ow",
        "outputId": "86940329-56e7-4cc6-ad18-02bae487b409"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.022545374929904938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rounding probabilities into 0 and 1 to compute accuracy, precision\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "predicted_classes = (y_pred_test > 0.5).int()\n",
        "\n",
        "y_true = y_test.squeeze().numpy()\n",
        "y_pred = predicted_classes.squeeze().numpy()\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3CN2iYKu1RW",
        "outputId": "006ec0a0-b72f-46bf-b4a8-8178d890c9cd"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1 Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9xlT9uwCeY1",
        "outputId": "5e39e5e8-6bf7-453f-b738-d01f5136acd0"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9806],\n",
              "        [0.9946],\n",
              "        [0.9910],\n",
              "        [0.9942],\n",
              "        [0.0293],\n",
              "        [0.0635]])"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuZhlZrEv8fy",
        "outputId": "20f0f037-0bc6-4231-9602-1523e8d6c7df"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scanpy"
      ],
      "metadata": {
        "id": "SC8EfT87wJYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To read the synthetic data\n",
        "import scanpy as sc\n",
        "adata = sc.read_h5ad(\"/content/drive/MyDrive/Colab Notebooks/processed_dataset_16genes.h5ad\")"
      ],
      "metadata": {
        "id": "ZDzU7OdMu1T8"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "phenotype_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/phenotypes_16gene.csv')"
      ],
      "metadata": {
        "id": "Tlt-n5HwxvRh"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phenotype_df.rename(columns={'Sample_ID': 'subject_id'}, inplace=True)"
      ],
      "metadata": {
        "id": "W8xKEPUK3A4D"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adata.obs['subject_id'] = adata.obs['subject_id'].astype(int)"
      ],
      "metadata": {
        "id": "SJVjlgg06zoE"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adata.obs = adata.obs.merge(phenotype_df, on='subject_id', how='left')"
      ],
      "metadata": {
        "id": "waegW2mc6zqz"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_subjects = adata.obs.groupby('subject_id')['binary_y'].unique()"
      ],
      "metadata": {
        "id": "Y70qhmD67vKp"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for subject_id, binary_y_values in unique_subjects.items(): print(f'Subject ID: {subject_id}, Binary Y: {binary_y_values}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmddJ7Uc7vM-",
        "outputId": "b7a19296-97ed-4aee-e9c1-25be7287465a"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject ID: 1, Binary Y: [1]\n",
            "Subject ID: 2, Binary Y: [0]\n",
            "Subject ID: 3, Binary Y: [1]\n",
            "Subject ID: 4, Binary Y: [0]\n",
            "Subject ID: 5, Binary Y: [0]\n",
            "Subject ID: 6, Binary Y: [0]\n",
            "Subject ID: 7, Binary Y: [0]\n",
            "Subject ID: 8, Binary Y: [1]\n",
            "Subject ID: 9, Binary Y: [0]\n",
            "Subject ID: 10, Binary Y: [0]\n",
            "Subject ID: 11, Binary Y: [0]\n",
            "Subject ID: 12, Binary Y: [0]\n",
            "Subject ID: 13, Binary Y: [0]\n",
            "Subject ID: 14, Binary Y: [1]\n",
            "Subject ID: 15, Binary Y: [0]\n",
            "Subject ID: 16, Binary Y: [1]\n",
            "Subject ID: 17, Binary Y: [0]\n",
            "Subject ID: 18, Binary Y: [0]\n",
            "Subject ID: 19, Binary Y: [0]\n",
            "Subject ID: 20, Binary Y: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To perform on the adata above\n",
        "\n",
        "embedding_dim = 4  #latent space dimension\n",
        "epochs = 100\n",
        "n_max = 500        #maximum number of cells per gene for each individual\n",
        "\n",
        "# 1.Extracting expression data and metadata\n",
        "expression_data = adata.X.toarray()\n",
        "subject_ids = adata.obs[\"subject_id\"].values\n",
        "phenotypes = adata.obs[\"binary_y\"].values\n",
        "\n",
        "\n",
        "n_individuals = len(set(subject_ids))\n",
        "n_genes = expression_data.shape[1]\n",
        "\n",
        "#To ensure correct phenotype order\n",
        "labels = []\n",
        "for individual_id in sorted(set(subject_ids)):\n",
        "    labels.append(np.unique(phenotypes[adata.obs[\"subject_id\"] == individual_id])[0])\n",
        "labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "\n",
        "#Placeholder for final embeddings: (n_individuals, n_genes * embedding_dim)\n",
        "final_embeddings = torch.empty((n_individuals, n_genes * embedding_dim))\n",
        "\n",
        "\n",
        "\n",
        "# 2. Processing each gene\n",
        "for gene_idx in range(n_genes):\n",
        "    print(f\"Processing Gene {gene_idx + 1}/{n_genes}\")\n",
        "    current_gene_data = []\n",
        "\n",
        "    for individual_id in sorted(set(subject_ids)):\n",
        "        #Extracting cells for the current gene and individual\n",
        "        individual_cells = expression_data[subject_ids == individual_id, gene_idx]\n",
        "\n",
        "\n",
        "        if len(individual_cells) > n_max:\n",
        "            individual_cells = individual_cells[:n_max]\n",
        "\n",
        "        #To pad with zeros if fewer than n_max (?????????????should I do it? since I think it is okay for sets to have different length)\n",
        "        padded_cells = torch.zeros(n_max)\n",
        "        padded_cells[:len(individual_cells)] = torch.tensor(individual_cells, dtype=torch.float32)\n",
        "\n",
        "\n",
        "        current_gene_data.append(padded_cells.unsqueeze(0))\n",
        "\n",
        "    #to stack all individuals' data for the current gene\n",
        "    current_gene_data = torch.cat(current_gene_data, dim=0)  # shape: (n_individuals, n_max)\n",
        "\n",
        "    #Scaling for the current gene (should be like this or all scaled before????????????????)\n",
        "    scaler = StandardScaler()\n",
        "    current_gene_data = torch.tensor(scaler.fit_transform(current_gene_data), dtype=torch.float32)\n",
        "\n",
        "    #initialization of autoencoder for the current gene\n",
        "    model = AutoEncoder(dim=n_max, hidden_dim=embedding_dim, max_n=n_max)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    #batch indices for individuals\n",
        "    batch = torch.arange(0, n_individuals)\n",
        "\n",
        "    #Training\n",
        "    torch.manual_seed(641555)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #forard\n",
        "        _, batchr = model(current_gene_data, batch)\n",
        "        loss = model.loss()[\"loss\"]\n",
        "\n",
        "        #backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "    #to extract latent embeddings for the current gene\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model.encoder(current_gene_data, batch)  # Shape: (n_individuals, embedding_dim)\n",
        "\n",
        "    final_embeddings[:, gene_idx * embedding_dim:(gene_idx + 1) * embedding_dim] = z\n",
        "\n",
        "\n",
        "print(\"Final Embeddings Shape:\", final_embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVSRYT9hBgaF",
        "outputId": "f019e3bf-15ee-43bb-bae5-15f77e49dad1"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Gene 1/16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
            "  c /= stddev[None, :]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 2.136932134628296\n",
            "Epoch 20/100, Loss: 1.9801450967788696\n",
            "Epoch 30/100, Loss: 1.6293604373931885\n",
            "Epoch 40/100, Loss: 1.3690032958984375\n",
            "Epoch 50/100, Loss: 1.09722101688385\n",
            "Epoch 60/100, Loss: 0.9792564511299133\n",
            "Epoch 70/100, Loss: 0.8703702688217163\n",
            "Epoch 80/100, Loss: 0.6350077390670776\n",
            "Epoch 90/100, Loss: 0.44168153405189514\n",
            "Epoch 100/100, Loss: 0.26999136805534363\n",
            "Processing Gene 2/16\n",
            "Epoch 10/100, Loss: 1.7738698720932007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 1.7124788761138916\n",
            "Epoch 30/100, Loss: 1.6508716344833374\n",
            "Epoch 40/100, Loss: 1.5894529819488525\n",
            "Epoch 50/100, Loss: 1.5284219980239868\n",
            "Epoch 60/100, Loss: 1.4678926467895508\n",
            "Epoch 70/100, Loss: 1.4079617261886597\n",
            "Epoch 80/100, Loss: 1.3487228155136108\n",
            "Epoch 90/100, Loss: 1.2902724742889404\n",
            "Epoch 100/100, Loss: 1.2327101230621338\n",
            "Processing Gene 3/16\n",
            "Epoch 10/100, Loss: 1.6786295175552368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 1.6092067956924438\n",
            "Epoch 30/100, Loss: 1.5409666299819946\n",
            "Epoch 40/100, Loss: 1.4730186462402344\n",
            "Epoch 50/100, Loss: 1.4056642055511475\n",
            "Epoch 60/100, Loss: 1.339032769203186\n",
            "Epoch 70/100, Loss: 1.273248314857483\n",
            "Epoch 80/100, Loss: 1.2084264755249023\n",
            "Epoch 90/100, Loss: 1.144680142402649\n",
            "Epoch 100/100, Loss: 1.0821192264556885\n",
            "Processing Gene 4/16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 2.2635061740875244\n",
            "Epoch 20/100, Loss: 1.6364902257919312\n",
            "Epoch 30/100, Loss: 1.5718129873275757\n",
            "Epoch 40/100, Loss: 1.5032906532287598\n",
            "Epoch 50/100, Loss: 1.434208869934082\n",
            "Epoch 60/100, Loss: 1.3656307458877563\n",
            "Epoch 70/100, Loss: 1.297926664352417\n",
            "Epoch 80/100, Loss: 1.231266975402832\n",
            "Epoch 90/100, Loss: 1.1657636165618896\n",
            "Epoch 100/100, Loss: 1.101517677307129\n",
            "Processing Gene 5/16\n",
            "Epoch 10/100, Loss: 1.6703050136566162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 1.6015784740447998\n",
            "Epoch 30/100, Loss: 1.533276915550232\n",
            "Epoch 40/100, Loss: 1.4655182361602783\n",
            "Epoch 50/100, Loss: 1.3984181880950928\n",
            "Epoch 60/100, Loss: 1.332089900970459\n",
            "Epoch 70/100, Loss: 1.2666406631469727\n",
            "Epoch 80/100, Loss: 1.202176809310913\n",
            "Epoch 90/100, Loss: 1.1388018131256104\n",
            "Epoch 100/100, Loss: 1.0766170024871826\n",
            "Processing Gene 6/16\n",
            "Epoch 10/100, Loss: 1.8740612268447876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 1.819695234298706\n",
            "Epoch 30/100, Loss: 1.7658361196517944\n",
            "Epoch 40/100, Loss: 1.7120122909545898\n",
            "Epoch 50/100, Loss: 1.6582467555999756\n",
            "Epoch 60/100, Loss: 1.6046168804168701\n",
            "Epoch 70/100, Loss: 1.5512102842330933\n",
            "Epoch 80/100, Loss: 1.4981205463409424\n",
            "Epoch 90/100, Loss: 1.4454418420791626\n",
            "Epoch 100/100, Loss: 1.3932713270187378\n",
            "Processing Gene 7/16\n",
            "Epoch 10/100, Loss: 1.6704305410385132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 1.6012239456176758\n",
            "Epoch 30/100, Loss: 1.5325982570648193\n",
            "Epoch 40/100, Loss: 1.4645700454711914\n",
            "Epoch 50/100, Loss: 1.3972463607788086\n",
            "Epoch 60/100, Loss: 1.3307311534881592\n",
            "Epoch 70/100, Loss: 1.2651269435882568\n",
            "Epoch 80/100, Loss: 1.2005339860916138\n",
            "Epoch 90/100, Loss: 1.1370527744293213\n",
            "Epoch 100/100, Loss: 1.0747833251953125\n",
            "Processing Gene 8/16\n",
            "Epoch 10/100, Loss: 1.6711947917938232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 1.6013637781143188\n",
            "Epoch 30/100, Loss: 1.5329160690307617\n",
            "Epoch 40/100, Loss: 1.4650394916534424\n",
            "Epoch 50/100, Loss: 1.3978416919708252\n",
            "Epoch 60/100, Loss: 1.3314317464828491\n",
            "Epoch 70/100, Loss: 1.2659145593643188\n",
            "Epoch 80/100, Loss: 1.2013938426971436\n",
            "Epoch 90/100, Loss: 1.1379718780517578\n",
            "Epoch 100/100, Loss: 1.075749158859253\n",
            "Processing Gene 9/16\n",
            "Epoch 10/100, Loss: 1.773400068283081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 1.7652534246444702\n",
            "Epoch 30/100, Loss: 1.7076332569122314\n",
            "Epoch 40/100, Loss: 1.6499792337417603\n",
            "Epoch 50/100, Loss: 1.5925753116607666\n",
            "Epoch 60/100, Loss: 1.5355145931243896\n",
            "Epoch 70/100, Loss: 1.478797197341919\n",
            "Epoch 80/100, Loss: 1.4225585460662842\n",
            "Epoch 90/100, Loss: 1.3668978214263916\n",
            "Epoch 100/100, Loss: 1.311919927597046\n",
            "Processing Gene 10/16\n",
            "Epoch 10/100, Loss: 1.727140188217163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 1.663393259048462\n",
            "Epoch 30/100, Loss: 1.5993868112564087\n",
            "Epoch 40/100, Loss: 1.5355117321014404\n",
            "Epoch 50/100, Loss: 1.472017526626587\n",
            "Epoch 60/100, Loss: 1.409062385559082\n",
            "Epoch 70/100, Loss: 1.3467719554901123\n",
            "Epoch 80/100, Loss: 1.28525972366333\n",
            "Epoch 90/100, Loss: 1.224632978439331\n",
            "Epoch 100/100, Loss: 1.16499662399292\n",
            "Processing Gene 11/16\n",
            "Epoch 10/100, Loss: 1.7218058109283447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 1.6560437679290771\n",
            "Epoch 30/100, Loss: 1.5908753871917725\n",
            "Epoch 40/100, Loss: 1.5262064933776855\n",
            "Epoch 50/100, Loss: 1.4621213674545288\n",
            "Epoch 60/100, Loss: 1.3987044095993042\n",
            "Epoch 70/100, Loss: 1.336043119430542\n",
            "Epoch 80/100, Loss: 1.274228811264038\n",
            "Epoch 90/100, Loss: 1.2133572101593018\n",
            "Epoch 100/100, Loss: 1.1535266637802124\n",
            "Processing Gene 12/16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 1.6703193187713623\n",
            "Epoch 20/100, Loss: 1.6013996601104736\n",
            "Epoch 30/100, Loss: 1.5329158306121826\n",
            "Epoch 40/100, Loss: 1.4649977684020996\n",
            "Epoch 50/100, Loss: 1.3977611064910889\n",
            "Epoch 60/100, Loss: 1.331315279006958\n",
            "Epoch 70/100, Loss: 1.2657657861709595\n",
            "Epoch 80/100, Loss: 1.2012165784835815\n",
            "Epoch 90/100, Loss: 1.1377698183059692\n",
            "Epoch 100/100, Loss: 1.0755268335342407\n",
            "Processing Gene 13/16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 1.721121072769165\n",
            "Epoch 20/100, Loss: 1.6560001373291016\n",
            "Epoch 30/100, Loss: 1.5912107229232788\n",
            "Epoch 40/100, Loss: 1.526841640472412\n",
            "Epoch 50/100, Loss: 1.462988018989563\n",
            "Epoch 60/100, Loss: 1.3997459411621094\n",
            "Epoch 70/100, Loss: 1.3372142314910889\n",
            "Epoch 80/100, Loss: 1.275493860244751\n",
            "Epoch 90/100, Loss: 1.2146857976913452\n",
            "Epoch 100/100, Loss: 1.0776408910751343\n",
            "Processing Gene 14/16\n",
            "Epoch 10/100, Loss: 1.670336365699768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 1.6015760898590088\n",
            "Epoch 30/100, Loss: 1.5332634449005127\n",
            "Epoch 40/100, Loss: 1.4654967784881592\n",
            "Epoch 50/100, Loss: 1.398390293121338\n",
            "Epoch 60/100, Loss: 1.332056999206543\n",
            "Epoch 70/100, Loss: 1.2666032314300537\n",
            "Epoch 80/100, Loss: 1.202135682106018\n",
            "Epoch 90/100, Loss: 1.1387571096420288\n",
            "Epoch 100/100, Loss: 1.0765697956085205\n",
            "Processing Gene 15/16\n",
            "Epoch 10/100, Loss: 1.670692801475525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 1.6014978885650635\n",
            "Epoch 30/100, Loss: 1.5327601432800293\n",
            "Epoch 40/100, Loss: 1.4646713733673096\n",
            "Epoch 50/100, Loss: 1.3972933292388916\n",
            "Epoch 60/100, Loss: 1.3307337760925293\n",
            "Epoch 70/100, Loss: 1.2650907039642334\n",
            "Epoch 80/100, Loss: 1.2004634141921997\n",
            "Epoch 90/100, Loss: 1.1369515657424927\n",
            "Epoch 100/100, Loss: 1.0746541023254395\n",
            "Processing Gene 16/16\n",
            "Epoch 10/100, Loss: 1.6703145503997803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/content/sae/sae/sae_model.py:52: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
            "  xr_var = xr.var(dim=0).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 1.6015806198120117\n",
            "Epoch 30/100, Loss: 1.5332773923873901\n",
            "Epoch 40/100, Loss: 1.4655174016952515\n",
            "Epoch 50/100, Loss: 1.3984166383743286\n",
            "Epoch 60/100, Loss: 1.332087516784668\n",
            "Epoch 70/100, Loss: 1.266637921333313\n",
            "Epoch 80/100, Loss: 1.2021733522415161\n",
            "Epoch 90/100, Loss: 1.1387979984283447\n",
            "Epoch 100/100, Loss: 1.0766133069992065\n",
            "Final Embeddings Shape: torch.Size([20, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train and testing preparation\n",
        "x_train, x_test, y_train, y_test = train_test_split(final_embeddings.detach().numpy(), labels.numpy(), test_size=0.2, random_state=1055)\n",
        "\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
      ],
      "metadata": {
        "id": "Wxq6FAQ_CRm0"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The MLP part\n",
        "input_dim = final_embeddings.shape[1]\n",
        "hidden_dim = 12\n",
        "model = GeneInteractionNN(input_dim, hidden_dim)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(x_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At2eQr1AGOwc",
        "outputId": "067cc9a3-b188-42cb-cc57-3faaa202c73f"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 0.5285037159919739\n",
            "Epoch 20/100, Loss: 0.4578450322151184\n",
            "Epoch 30/100, Loss: 0.3982967734336853\n",
            "Epoch 40/100, Loss: 0.3443358540534973\n",
            "Epoch 50/100, Loss: 0.29556071758270264\n",
            "Epoch 60/100, Loss: 0.25395771861076355\n",
            "Epoch 70/100, Loss: 0.21773545444011688\n",
            "Epoch 80/100, Loss: 0.18595059216022491\n",
            "Epoch 90/100, Loss: 0.15882326662540436\n",
            "Epoch 100/100, Loss: 0.13613905012607574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_test = model(x_test)\n",
        "    test_loss = criterion(y_pred_test, y_test)\n",
        "    print(f\"Test Loss: {test_loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9H4Rq2IGTch",
        "outputId": "4005ed86-68ed-409c-9c35-786368b53c9a"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.12266811728477478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rounding probabilities into 0 and 1 to compute accuracy, precision\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "predicted_classes = (y_pred_test > 0.5).int()\n",
        "\n",
        "\n",
        "y_true = y_test.squeeze().numpy()\n",
        "y_pred = predicted_classes.squeeze().numpy()\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STUY6vvIGUrc",
        "outputId": "704ee36f-1d63-466a-cd2e-1a7db68d2407"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1 Score: 1.00\n"
          ]
        }
      ]
    }
  ]
}